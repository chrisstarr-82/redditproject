{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into my reddit account with PRAW API for data collection\n",
    "#reddit = praw.Reddit(\n",
    "    # personal use script\n",
    "#    client_id = (removed),\n",
    "    #secret\n",
    "#    client_secret = (removed),\n",
    "    # account pw\n",
    "#    password = (removed),\n",
    "#    username = (removed),\n",
    "#    user_agent = 'project script'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cds_serious\n"
     ]
    }
   ],
   "source": [
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate lists used to hold subreddit data from scrapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the lists\n",
    "ids = []\n",
    "title = []\n",
    "body = []\n",
    "num_comments = []\n",
    "upvotes = []\n",
    "time_posted = []\n",
    "time_now = []\n",
    "time_delta = []\n",
    "subreddits = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- subreddits: r/vegan   r/Cooking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach**: *I am using the r/vegan and r/Cooking subreddits to analyze a question related to personal identity and values. The top posts and controversial posts will show what the posters on the subreddits are interested in promoting or arguing about, so much of the data will be from these posts. Due to the limited amount of data that can be collected at one time with PRAW and the fact that r/vegan has a limited amount of text data, I need to collect data from many of the time options available for controversial and top posts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for data collection. Append data to the lists created above.\n",
    "def collect_data(selection):    \n",
    "    # loop through reddit posts\n",
    "    for submission in selection:\n",
    "        # update the lists as we go\n",
    "        # id\n",
    "        ids.append(submission.id)\n",
    "        # title appearing on the front page\n",
    "        title.append(submission.title)\n",
    "        # the submissions' body - an empty str if a link post\n",
    "        body.append(submission.selftext)\n",
    "        # number of comments\n",
    "        num_comments.append(submission.num_comments)\n",
    "        # number of upvotes\n",
    "        upvotes.append(submission.ups)\n",
    "        # time the reddit was created\n",
    "        time_posted.append(submission.created_utc)\n",
    "        # time that reddit was scraped\n",
    "        time_now.append(datetime.datetime.utcnow())\n",
    "        # time elapsed\n",
    "        time_delta.append(datetime.datetime.utcnow() - \\\n",
    "                          datetime.datetime.utcfromtimestamp(submission.created_utc)) \n",
    "        # subreddit. Target variable.\n",
    "        subreddits.append(submission.subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "collect_data(reddit.subreddit('vegan').controversial('all', limit = 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 999 999 999 999 999 999 999 999\n"
     ]
    }
   ],
   "source": [
    "# lists need to be of the same length for dataframe creation. Conclusion is that the function put\n",
    "# the same amount of data into each list.\n",
    "print(len(ids), len(title), len(body), len(subreddits), len(num_comments),\n",
    "      len(upvotes), len(time_posted), len(time_now), len(time_delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consideration of the server**: Information about running multiple PRAW requests is found here: https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html It is unclear how many can be run at once, and I want to be careful. The documentation says \"PRAW, as of version 4, performs rate limiting dynamically based on the HTTP response headers from Reddit. As a result you can safely run a handful of PRAW instances without any additional configuration.\" I will only put a few data collection requests in each cell and will wait a little while between running cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referred to https://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html for time options for \n",
    "# controversial posts\n",
    "# r/vegan is only moderately large and active. Requesting data for shorter than a month will not add new data.\n",
    "collect_data(reddit.subreddit('vegan').controversial('year', limit = None))\n",
    "collect_data(reddit.subreddit('vegan').controversial('month', limit = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referred to https://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html for time options for \n",
    "# top posts\n",
    "# r/vegan is only moderately large and active. Requesting data for shorter than a month will not add new data.\n",
    "collect_data(reddit.subreddit('vegan').top('all', limit = None))\n",
    "collect_data(reddit.subreddit('vegan').top('year', limit = None))\n",
    "collect_data(reddit.subreddit('vegan').top('month', limit = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the same data for r/Cooking so that the subreddits can be compared more accurately\n",
    "collect_data(reddit.subreddit('Cooking').controversial('all', limit = None))\n",
    "collect_data(reddit.subreddit('Cooking').controversial('year', limit = None))\n",
    "collect_data(reddit.subreddit('Cooking').controversial('month', limit = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data(reddit.subreddit('Cooking').top('all', limit = None))\n",
    "collect_data(reddit.subreddit('Cooking').top('year', limit = None))\n",
    "collect_data(reddit.subreddit('Cooking').top('month', limit = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To maximize the amount of data, also collect new posts from both of the subreddits\n",
    "collect_data(reddit.subreddit('vegan').new(limit = None))\n",
    "collect_data(reddit.subreddit('Cooking').new(limit = None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic processing and analysis of the first batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>time_posted</th>\n",
       "      <th>time_now</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n3vd33</td>\n",
       "      <td>\"But We Always Ate Meat,\"</td>\n",
       "      <td></td>\n",
       "      <td>1178</td>\n",
       "      <td>0</td>\n",
       "      <td>1.620047e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594675</td>\n",
       "      <td>12 days 22:37:48.594680</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aydjra</td>\n",
       "      <td>üòé</td>\n",
       "      <td></td>\n",
       "      <td>769</td>\n",
       "      <td>938</td>\n",
       "      <td>1.551971e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594689</td>\n",
       "      <td>800 days 20:31:30.594689</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eqdom7</td>\n",
       "      <td>Hypocrites</td>\n",
       "      <td></td>\n",
       "      <td>1330</td>\n",
       "      <td>919</td>\n",
       "      <td>1.579334e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594693</td>\n",
       "      <td>484 days 03:39:40.594694</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>au03xj</td>\n",
       "      <td>I hope this fits here</td>\n",
       "      <td></td>\n",
       "      <td>946</td>\n",
       "      <td>2672</td>\n",
       "      <td>1.550956e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594697</td>\n",
       "      <td>812 days 14:31:36.594697</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ahdew</td>\n",
       "      <td>was told this went here.</td>\n",
       "      <td></td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>1.363553e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594701</td>\n",
       "      <td>2981 days 15:00:14.594702</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                      title body  num_comments  upvotes  \\\n",
       "0  n3vd33  \"But We Always Ate Meat,\"               1178        0   \n",
       "1  aydjra                          üòé                769      938   \n",
       "2  eqdom7                 Hypocrites               1330      919   \n",
       "3  au03xj      I hope this fits here                946     2672   \n",
       "4  1ahdew   was told this went here.                208        0   \n",
       "\n",
       "    time_posted                   time_now                time_delta subreddit  \n",
       "0  1.620047e+09 2021-05-16 11:36:28.594675   12 days 22:37:48.594680     vegan  \n",
       "1  1.551971e+09 2021-05-16 11:36:28.594689  800 days 20:31:30.594689     vegan  \n",
       "2  1.579334e+09 2021-05-16 11:36:28.594693  484 days 03:39:40.594694     vegan  \n",
       "3  1.550956e+09 2021-05-16 11:36:28.594697  812 days 14:31:36.594697     vegan  \n",
       "4  1.363553e+09 2021-05-16 11:36:28.594701 2981 days 15:00:14.594702     vegan  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put into a DataFrame\n",
    "df = pd.DataFrame({'id': ids, 'title': title, 'body': body, 'num_comments': num_comments,\n",
    "                   'upvotes': upvotes, 'time_posted': time_posted,\n",
    "                   'time_now': time_now, 'time_delta': time_delta,\n",
    "                   'subreddit': subreddits})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for the length of the body text. The length is 1 for an empty column.\n",
    "df['text_length'] = [len(x.split(' ')) for x in df.body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>time_posted</th>\n",
       "      <th>time_now</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jvq4pp</td>\n",
       "      <td>PSA: If you hate PETA, that's because a right ...</td>\n",
       "      <td>A huge smear campaign started by \\n\\nPeta Kill...</td>\n",
       "      <td>901</td>\n",
       "      <td>2829</td>\n",
       "      <td>1.605605e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594755</td>\n",
       "      <td>180 days 02:07:37.594756</td>\n",
       "      <td>vegan</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>114zvn</td>\n",
       "      <td>I was a Vegan for several months until this pa...</td>\n",
       "      <td>They said that the goats ate only fresh goat f...</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1.349707e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594762</td>\n",
       "      <td>3141 days 21:06:08.594763</td>\n",
       "      <td>vegan</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lenglo</td>\n",
       "      <td>why are vegan subs so cowardly when it comes t...</td>\n",
       "      <td>~~I‚Äôm pretty sure I was just quietly banned~~ ...</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.612708e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594795</td>\n",
       "      <td>97 days 21:07:42.594795</td>\n",
       "      <td>vegan</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ixiq4p</td>\n",
       "      <td>White Veganism and Why it's Problematic</td>\n",
       "      <td>Personally, I'm a person of color and it frust...</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.600759e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594806</td>\n",
       "      <td>236 days 04:18:37.594806</td>\n",
       "      <td>vegan</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>giowc5</td>\n",
       "      <td>tired of cigarette smokers calling themselves ...</td>\n",
       "      <td>you literally can‚Äôt smoke cigarettes and be a ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.589333e+09</td>\n",
       "      <td>2021-05-16 11:36:28.594824</td>\n",
       "      <td>368 days 10:20:15.594824</td>\n",
       "      <td>vegan</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "19  jvq4pp  PSA: If you hate PETA, that's because a right ...   \n",
       "21  114zvn  I was a Vegan for several months until this pa...   \n",
       "29  lenglo  why are vegan subs so cowardly when it comes t...   \n",
       "32  ixiq4p            White Veganism and Why it's Problematic   \n",
       "37  giowc5  tired of cigarette smokers calling themselves ...   \n",
       "\n",
       "                                                 body  num_comments  upvotes  \\\n",
       "19  A huge smear campaign started by \\n\\nPeta Kill...           901     2829   \n",
       "21  They said that the goats ate only fresh goat f...           239        0   \n",
       "29  ~~I‚Äôm pretty sure I was just quietly banned~~ ...            75        3   \n",
       "32  Personally, I'm a person of color and it frust...            64        0   \n",
       "37  you literally can‚Äôt smoke cigarettes and be a ...            14        1   \n",
       "\n",
       "     time_posted                   time_now                time_delta  \\\n",
       "19  1.605605e+09 2021-05-16 11:36:28.594755  180 days 02:07:37.594756   \n",
       "21  1.349707e+09 2021-05-16 11:36:28.594762 3141 days 21:06:08.594763   \n",
       "29  1.612708e+09 2021-05-16 11:36:28.594795   97 days 21:07:42.594795   \n",
       "32  1.600759e+09 2021-05-16 11:36:28.594806  236 days 04:18:37.594806   \n",
       "37  1.589333e+09 2021-05-16 11:36:28.594824  368 days 10:20:15.594824   \n",
       "\n",
       "   subreddit  text_length  \n",
       "19     vegan          285  \n",
       "21     vegan          325  \n",
       "29     vegan          299  \n",
       "32     vegan          383  \n",
       "37     vegan           89  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the empty body columns, which are the ones with links and images\n",
    "df = df[df.text_length != 1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8365, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows I got in the initial data collection\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate posts in the dataset and check the number of rows\n",
    "df.drop_duplicates(subset = ['title', 'body', 'subreddit'],\n",
    "                   inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cooking    4443\n",
       "vegan      1893\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution between subreddits\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: There is enough data for NLP analysis. I will collect more over the coming days though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cooking    0.701231\n",
       "vegan      0.298769\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: There is a 70-30 split between classes, which is unbalanced but not too unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial batch of data\n",
    "df.to_csv('./saved_data/first_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data from new posts\n",
    "collect_data(reddit.subreddit('vegan').new(limit = None))\n",
    "collect_data(reddit.subreddit('Cooking').new(limit = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>time_posted</th>\n",
       "      <th>time_now</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nfsvk0</td>\n",
       "      <td>The Search for the Vegan Violin</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.621390e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293838</td>\n",
       "      <td>0 days 00:03:06.293843</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nfsc5l</td>\n",
       "      <td>Worried about my parents eating habits...</td>\n",
       "      <td>hi everybody! I am a vegan college student and...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.621388e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293852</td>\n",
       "      <td>0 days 00:28:17.293852</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nfs98w</td>\n",
       "      <td>‚ÄúWe should have a choice‚Äù</td>\n",
       "      <td>I‚Äôm just wondering how people respond to this ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.621388e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293856</td>\n",
       "      <td>0 days 00:32:10.293857</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nfr5ro</td>\n",
       "      <td>Prepackaged depression meal but make it ~healthy~</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.621385e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293860</td>\n",
       "      <td>0 days 01:23:43.293860</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nfr8sw</td>\n",
       "      <td>Duo Lingo Knows</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.621385e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293864</td>\n",
       "      <td>0 days 01:19:52.293864</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  nfsvk0                    The Search for the Vegan Violin   \n",
       "1  nfsc5l          Worried about my parents eating habits...   \n",
       "2  nfs98w                          ‚ÄúWe should have a choice‚Äù   \n",
       "3  nfr5ro  Prepackaged depression meal but make it ~healthy~   \n",
       "4  nfr8sw                                    Duo Lingo Knows   \n",
       "\n",
       "                                                body  num_comments  upvotes  \\\n",
       "0                                                                0        1   \n",
       "1  hi everybody! I am a vegan college student and...             2        2   \n",
       "2  I‚Äôm just wondering how people respond to this ...             7        3   \n",
       "3                                                                1       12   \n",
       "4                                                                0        6   \n",
       "\n",
       "    time_posted                   time_now             time_delta subreddit  \n",
       "0  1.621390e+09 2021-05-19 02:02:44.293838 0 days 00:03:06.293843     vegan  \n",
       "1  1.621388e+09 2021-05-19 02:02:44.293852 0 days 00:28:17.293852     vegan  \n",
       "2  1.621388e+09 2021-05-19 02:02:44.293856 0 days 00:32:10.293857     vegan  \n",
       "3  1.621385e+09 2021-05-19 02:02:44.293860 0 days 01:23:43.293860     vegan  \n",
       "4  1.621385e+09 2021-05-19 02:02:44.293864 0 days 01:19:52.293864     vegan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put into a DataFrame\n",
    "df = pd.DataFrame({'id': ids, 'title': title, 'body': body, 'num_comments': num_comments,\n",
    "                   'upvotes': upvotes, 'time_posted': time_posted,\n",
    "                   'time_now': time_now, 'time_delta': time_delta,\n",
    "                   'subreddit': subreddits})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for the length of the body text. The length is 1 for an empty column.\n",
    "df['text_length'] = [len(x.split(' ')) for x in df.body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>time_posted</th>\n",
       "      <th>time_now</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nfsc5l</td>\n",
       "      <td>Worried about my parents eating habits...</td>\n",
       "      <td>hi everybody! I am a vegan college student and...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.621388e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293852</td>\n",
       "      <td>0 days 00:28:17.293852</td>\n",
       "      <td>vegan</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nfs98w</td>\n",
       "      <td>‚ÄúWe should have a choice‚Äù</td>\n",
       "      <td>I‚Äôm just wondering how people respond to this ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.621388e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293856</td>\n",
       "      <td>0 days 00:32:10.293857</td>\n",
       "      <td>vegan</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nfr87k</td>\n",
       "      <td>I‚Äôm considering going Vegan, but I have a ques...</td>\n",
       "      <td>How much of the meat industry is cruel? Especi...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.621385e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293882</td>\n",
       "      <td>0 days 01:20:36.293882</td>\n",
       "      <td>vegan</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nfqxqq</td>\n",
       "      <td>TOFU</td>\n",
       "      <td>Hey.. so I‚Äôm terrified of tofu. I‚Äôve always av...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.621384e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293886</td>\n",
       "      <td>0 days 01:33:56.293886</td>\n",
       "      <td>vegan</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nfqs3w</td>\n",
       "      <td>Has anyone seen the new Impossible Burger 6-pa...</td>\n",
       "      <td>According to [this article](https://www.onegre...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.621384e+09</td>\n",
       "      <td>2021-05-19 02:02:44.293889</td>\n",
       "      <td>0 days 01:41:13.293890</td>\n",
       "      <td>vegan</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "1   nfsc5l          Worried about my parents eating habits...   \n",
       "2   nfs98w                          ‚ÄúWe should have a choice‚Äù   \n",
       "8   nfr87k  I‚Äôm considering going Vegan, but I have a ques...   \n",
       "9   nfqxqq                                               TOFU   \n",
       "10  nfqs3w  Has anyone seen the new Impossible Burger 6-pa...   \n",
       "\n",
       "                                                 body  num_comments  upvotes  \\\n",
       "1   hi everybody! I am a vegan college student and...             2        2   \n",
       "2   I‚Äôm just wondering how people respond to this ...             7        3   \n",
       "8   How much of the meat industry is cruel? Especi...            12        3   \n",
       "9   Hey.. so I‚Äôm terrified of tofu. I‚Äôve always av...             5        0   \n",
       "10  According to [this article](https://www.onegre...             4        3   \n",
       "\n",
       "     time_posted                   time_now             time_delta subreddit  \\\n",
       "1   1.621388e+09 2021-05-19 02:02:44.293852 0 days 00:28:17.293852     vegan   \n",
       "2   1.621388e+09 2021-05-19 02:02:44.293856 0 days 00:32:10.293857     vegan   \n",
       "8   1.621385e+09 2021-05-19 02:02:44.293882 0 days 01:20:36.293882     vegan   \n",
       "9   1.621384e+09 2021-05-19 02:02:44.293886 0 days 01:33:56.293886     vegan   \n",
       "10  1.621384e+09 2021-05-19 02:02:44.293889 0 days 01:41:13.293890     vegan   \n",
       "\n",
       "    text_length  \n",
       "1           124  \n",
       "2            96  \n",
       "8           115  \n",
       "9            65  \n",
       "10           41  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the empty body columns, which are the ones with links and images\n",
    "df = df[df.text_length != 1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1331, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows I got in the initial data collection\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate posts in the dataset and check the number of rows\n",
    "df.drop_duplicates(subset = ['title', 'body', 'subreddit'],\n",
    "                   inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cooking    923\n",
       "vegan      407\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution between subreddits\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cooking    0.693985\n",
       "vegan      0.306015\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: we get a similar 70-30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv('./saved_data/first_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7666, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the full dataset\n",
    "df_current = pd.concat([df_old,df])\n",
    "df_current.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full dataset\n",
    "df_current.to_csv('./saved_data/second_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
